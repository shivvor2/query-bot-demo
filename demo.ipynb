{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query LLM bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Installs required libraries\n",
    "# %pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load enviromental variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consumption Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "names = ['Jake', 'Paul', 'Evan', 'Sarah', 'Emma', 'Michael', 'Lisa', 'David', 'Rachel', 'Alex']\n",
    "foods = ['French-fries', 'Pizza', 'Burger', 'Sushi', 'Pasta', 'Salad', 'Ice Cream', 'Tacos', 'Sandwich', 'Chicken Wings']\n",
    "\n",
    "data = {name: [random.randint(0, 10) for _ in range(len(foods))] for name in names}\n",
    "\n",
    "df = pd.DataFrame(data, index=foods)\n",
    "\n",
    "df.to_csv('food_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jake</th>\n",
       "      <th>Paul</th>\n",
       "      <th>Evan</th>\n",
       "      <th>Sarah</th>\n",
       "      <th>Emma</th>\n",
       "      <th>Michael</th>\n",
       "      <th>Lisa</th>\n",
       "      <th>David</th>\n",
       "      <th>Rachel</th>\n",
       "      <th>Alex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>French-fries</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pizza</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burger</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sushi</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pasta</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salad</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ice Cream</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tacos</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sandwich</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicken Wings</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Jake  Paul  Evan  Sarah  Emma  Michael  Lisa  David  Rachel  \\\n",
       "French-fries      4     5     5      6     1        8     1      7       9   \n",
       "Pizza             1     5     7      7    10       10     1      4       6   \n",
       "Burger            8    10     0      2     9        4     5      3       7   \n",
       "Sushi             3     0     9      8     5        7     3      2       2   \n",
       "Pasta             2     3     6      1     0        4     8      4       4   \n",
       "Salad             7     0     2      1     6        2     0      0      10   \n",
       "Ice Cream         2     5     8      5     4        4     3      3       2   \n",
       "Tacos             3     5     6      9     9        1     2      7      10   \n",
       "Sandwich          4     4     1      5     2        8     9      9       1   \n",
       "Chicken Wings     6     8     8      4     9        2     7      3       1   \n",
       "\n",
       "               Alex  \n",
       "French-fries      7  \n",
       "Pizza             6  \n",
       "Burger            8  \n",
       "Sushi             9  \n",
       "Pasta             1  \n",
       "Salad             6  \n",
       "Ice Cream         5  \n",
       "Tacos             8  \n",
       "Sandwich          4  \n",
       "Chicken Wings     6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jake',\n",
       " 'Paul',\n",
       " 'Evan',\n",
       " 'Sarah',\n",
       " 'Emma',\n",
       " 'Michael',\n",
       " 'Lisa',\n",
       " 'David',\n",
       " 'Rachel',\n",
       " 'Alex']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['French-fries',\n",
       " 'Pizza',\n",
       " 'Burger',\n",
       " 'Sushi',\n",
       " 'Pasta',\n",
       " 'Salad',\n",
       " 'Ice Cream',\n",
       " 'Tacos',\n",
       " 'Sandwich',\n",
       " 'Chicken Wings']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food Descriptions\n",
    "\n",
    "To demonstrate querying from multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'French fries are crispy, golden-brown potato strips that are beloved worldwide as a classic side dish. Originally believed to have originated in Belgium, they are made by cutting potatoes into long strips and deep-frying them until crispy on the outside and fluffy on the inside. French fries have become a staple of fast food cuisine and are commonly served with various condiments like ketchup, mayonnaise, or vinegar.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"food_descriptions.json\", 'r') as f:\n",
    "    food_descriptions = json.load(f)\n",
    "    \n",
    "food_descriptions[\"French-fries\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Clients\n",
    "\n",
    "We will initialize the client and return a function that:\n",
    "- Takes in a message history\n",
    "- Returns a new message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Chat client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from response import get_response\n",
    "\n",
    "client = OpenAI(base_url = os.getenv(\"BASE_URL\"), api_key = os.getenv(\"API_KEY\"))\n",
    "\n",
    "client_args = {\n",
    "    \"model\": \"anthropic/claude-3.5-sonnet:beta\",\n",
    "    \"temperature\": 0.6\n",
    "}\n",
    "\n",
    "chat_func = partial(get_response, client = client, client_args = client_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', \"The meaning of life is a philosophical and personal question that has been debated throughout human history. There is no single, universally accepted answer, as different people, cultures, and belief systems have varying perspectives. Here are some common interpretations:\\n\\n1. Religious perspectives: Many religions believe life's meaning is connected to serving a higher power and following spiritual teachings.\\n\\n2. Philosophical views:\\n- Existentialism: Creating your own meaning through choices and actions\\n- Nihilism: Life has no inherent meaning\\n- Humanism: Finding meaning through human experiences and relationships\\n\\n3. Scientific perspective: Biological continuation of species and evolution\\n\\n4. Personal fulfillment:\\n- Pursuing happiness\\n- Building relationships\\n- Achieving goals\\n- Contributing to society\\n- Personal growth\\n- Leaving a legacy\\n\\n5. Practical purposes:\\n- Learning and gaining knowledge\\n- Creating art and beauty\\n- Helping others\\n- Experiencing love and connection\\n\\nThe meaning of life is ultimately a personal journey of discovery, and individuals must determine what gives their life purpose and significance based on their own values, beliefs, and experiences.\")\n",
      "('role', 'assistant')\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "msg = {\"role\": \"user\", \"content\": \"What is the meaning of life\"}\n",
    "\n",
    "response = chat_func([msg])\n",
    "\n",
    "for item in response.items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured output/ tool calling client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import instructor\n",
    "from instructor import Instructor\n",
    "import os\n",
    "from functools import partial\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "client_structured_raw = OpenAI(base_url = os.getenv(\"BASE_URL\"), api_key = os.getenv(\"API_KEY\"))\n",
    "\n",
    "client_args_structured = {\n",
    "    \"model\": \"meta-llama/llama-3.2-3b-instruct\",\n",
    "    \"temperature\": 0.2\n",
    "}\n",
    "\n",
    "client_structured = instructor.from_openai(client_structured_raw, mode = instructor.Mode.JSON)\n",
    "\n",
    "def get_structured_outputs(messages: List[dict], response_model: BaseModel, client_structured: Instructor, client_args: dict):\n",
    "    response: BaseModel = client_structured.chat.completions.create(\n",
    "        messages = messages,\n",
    "        response_model = response_model,\n",
    "        **client_args\n",
    "    )\n",
    "    return response\n",
    "\n",
    "structured_func = partial(get_structured_outputs, client_structured = client_structured, client_args = client_args_structured)\n",
    "chat_func_debug = partial(get_response, client = client_structured_raw, client_args = client_args_structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('content', '{\"name\": \"Jason Lee\", \"age\": 54}')\n",
      "('role', 'assistant')\n",
      "Jason Lee\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "class Test(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    \n",
    "msg = {\"role\": \"user\", \n",
    "       \"content\": \"\"\"Please extract information from the following sentence: \n",
    "                     \"Jason Lee, a 7-11 worker, is now 54 years old\",\n",
    "                     Please respond in the following following structure, as a single line json/ dictionary:\n",
    "                     {\"name\": <the person's name>,\"age\": <integer age>}\"\"\"}\n",
    "\n",
    "response = chat_func_debug([msg])\n",
    "\n",
    "for item in response.items():\n",
    "    print(item)\n",
    "\n",
    "structured_output = structured_func([msg], Test)\n",
    "\n",
    "print(structured_output.name)\n",
    "print(structured_output.age) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1\n",
    "Stuff everything into the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the system prompt\n",
    "df_text = df.to_markdown()\n",
    "sys_prompt = f\"Please respond to user questions according to the following content: \\n Consumption information: {df_text} \\n Food descriptions: \\n {str(food_descriptions)} \\n Respond with the provided information only, if nessesary, think step by step\"\n",
    "\n",
    "sys_msg = {\"role\": \"system\", \"content\": sys_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def make_user_message_dict(new_message: str):\n",
    "    return {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": new_message\n",
    "    }\n",
    "\n",
    "def print_llm_message(message: dict):\n",
    "    print(f\"{message[\"role\"]}: {message[\"content\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: How many burgers did Evan ate?\n",
      "assistant: According to the table, Evan's rating for burgers is 0, which means he didn't eat any burgers.\n",
      "user: What is the total amount of food that Emma ate\n",
      "assistant: Let me add up Emma's ratings for all foods:\n",
      "\n",
      "1. French-fries: 1\n",
      "2. Pizza: 10\n",
      "3. Burger: 9\n",
      "4. Sushi: 5\n",
      "5. Pasta: 0\n",
      "6. Salad: 6\n",
      "7. Ice Cream: 4\n",
      "8. Tacos: 9\n",
      "9. Sandwich: 2\n",
      "10. Chicken Wings: 9\n",
      "\n",
      "1 + 10 + 9 + 5 + 0 + 6 + 4 + 9 + 2 + 9 = 55\n",
      "\n",
      "The total amount of food that Emma ate (based on her ratings) is 55.\n"
     ]
    }
   ],
   "source": [
    "message_history = [] # List of message dicts, can potentially feed in partially (e.g. max 20 recent messages)\n",
    "\n",
    "while True:\n",
    "    current_user_input = input(\"Send a message to the system (type \\\"quit\\\" to exit process): \")\n",
    "    if current_user_input == \"quit\":\n",
    "        message_history = []\n",
    "        break\n",
    "    current_msg = make_user_message_dict(current_user_input)\n",
    "    print_llm_message(current_msg)\n",
    "    message_history.append(current_msg)\n",
    "    new_msg = chat_func([sys_msg] + message_history)\n",
    "    print_llm_message(new_msg)\n",
    "    message_history.append(new_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2\n",
    "\n",
    "Retrieving information as needed (via an API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "def get_food_description(food: str):\n",
    "    return f\"{food}: \" + food_descriptions[food]\n",
    "\n",
    "def get_person_consumption_data(name: str):\n",
    "    return f\"{name}'s comsumption data: \\n\" + df[name].to_markdown()\n",
    "\n",
    "def get_food_consumption_data(food: str):\n",
    "    return f\"Comsumption data of food {food}: \\n\" + df.loc[food].to_markdown()\n",
    "\n",
    "# Example structured output: {\"type\": \"food_description\", \"query\": \"Ice Cream\"}, {\"type\": \"person\", \"query\": \"Rachel\"}\n",
    "def router_func(input: dict):\n",
    "    if input[\"type\"] == \"food_description\":\n",
    "        return get_food_description(input[\"query\"])\n",
    "    elif input[\"type\"] == \"person\":\n",
    "        return get_person_consumption_data(input[\"query\"])\n",
    "    elif input[\"type\"] == \"food\":\n",
    "        return get_food_consumption_data(input[\"query\"])\n",
    "    else:\n",
    "        print(f\"Error, no question type {input[\"type\"]} exists\")\n",
    "\n",
    "class Query(BaseModel):\n",
    "    type: str\n",
    "    query: str\n",
    "\n",
    "class QueryList(BaseModel):\n",
    "    root: List[Query] = Field(alias=\"queries\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_response(cls, completion, **kwargs):\n",
    "        if hasattr(completion, 'choices'):\n",
    "            content = completion.choices[0].message.content\n",
    "        else:\n",
    "            content = completion\n",
    "            \n",
    "        import json\n",
    "        import re\n",
    "        \n",
    "        # Extract JSON object using regex\n",
    "        json_match = re.search(r'\\{.*\\}', content)\n",
    "        if json_match:\n",
    "            try:\n",
    "                data = json.loads(json_match.group())\n",
    "                return cls(**data)\n",
    "            except json.JSONDecodeError as e:\n",
    "                raise ValueError(f\"Invalid JSON content: {json_match.group()}\") from e\n",
    "        else:\n",
    "            raise ValueError(f\"No JSON object found in content: {content}\")\n",
    "\n",
    "def process_queries(inputs: List[Query]):\n",
    "    result_list = []\n",
    "    for input in inputs:\n",
    "        input_dict = input.model_dump()\n",
    "        result = router_func(input_dict)\n",
    "        result_list.append(result)\n",
    "    return \"Retrieved Queries: \\n\"+ \"\\n\".join(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_structured = f\"\"\"\n",
    "You are a query generation assistant that creates structured outputs for a food consumption database. \n",
    "You MUST respond with a JSON object containing a 'queries' field that holds an array of query objects. The response MUST be in this exact format:\n",
    "{{\"queries\": [{{\"type\": \"food_description\", \"query\": \"food_name\"}}, {{\"type\": \"person\", \"query\": \"person_name\"}}]}}\n",
    "\n",
    "Available formats:\n",
    "1. For food descriptions: {{\"type\": \"food_description\", \"query\": \"<food>\"}}\n",
    "2. For person's consumption data: {{\"type\": \"person\", \"query\": \"<person_name>\"}}\n",
    "3. For food consumption data: {{\"type\": \"food\", \"query\": \"<food>\"}}\n",
    "\n",
    "For fields, please strictly follow the following instructions:\n",
    "- <food> MUST be one of {df.index.to_list()}\n",
    "- <person_name> MUST be one of {df.columns.to_list()}\n",
    "\n",
    "\n",
    "Remember: Always respond with a JSON object containing the 'queries' field, even if there's only one query.\n",
    "Example for single query: \n",
    "{{\"queries\": [{{\"type\": \"food_description\", \"query\": \"Pizza\"}}]}}\n",
    "\n",
    "Example for multiple queries: \n",
    "{{\"queries\": [{{\"type\": \"food_description\", \"query\": \"Pizza\"}}, {{\"type\": \"person\", \"query\": \"Rachel\"}}]}}\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt = \"Please respond to user questions, relevant information will be appended after each user message (retrieved via a retrieval module), only respond according to this information\"\n",
    "\n",
    "sys_msg_structured = {\"role\": \"system\", \"content\": sys_prompt_structured}\n",
    "sys_msg = {\"role\": \"system\", \"content\": sys_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '{\"queries\": [{\"type\": \"person\", \"query\": \"Evan\"}, {\"type\": \"food\", \"query\": \"Burger\"}]}', 'role': 'assistant'}\n",
      "root=[Query(type='person', query='Evan'), Query(type='food', query='Burger')]\n",
      "assistant: According to the consumption data, Evan ate 0 burgers.\n",
      "{'content': '{\"queries\": [{\"type\": \"person\", \"query\": \"Emma\"}, {\"type\": \"food\", \"query\": \"Pasta\"}, {\"type\": \"food\", \"query\": \"Burger\"}, {\"type\": \"food\", \"query\": \"Ice Cream\"}, {\"type\": \"food\", \"query\": \"Chicken Wings\"}]}\\n\\nNote: The response is in the required format, but the queries are not directly related to the original question. The correct response should be a single query object with the total amount of food that Emma ate. \\n\\nTo answer the question correctly, I need to calculate the total amount of food that Emma ate. According to the consumption data, Emma ate 0 burgers, 6 pasta, 8 ice cream, and 8 chicken wings. The total amount of food that Emma ate is 0 + 6 + 8 + 8 = 22. \\n\\nHowever, I need to follow the original format, so the correct response is:\\n\\n{\"queries\": [{\"type\": \"person\", \"query\": \"Emma\"}]}', 'role': 'assistant'}\n",
      "root=[Query(type='person', query='Emma'), Query(type='food_description', query='Pasta')]\n",
      "assistant: Based on Emma's consumption data, the total amount of food she ate is:\n",
      "1 (French-fries) + 10 (Pizza) + 9 (Burger) + 5 (Sushi) + 0 (Pasta) + 6 (Salad) + 4 (Ice Cream) + 9 (Tacos) + 2 (Sandwich) + 9 (Chicken Wings) = 55 items in total.\n"
     ]
    }
   ],
   "source": [
    "message_history = [] # List of message dicts, can potentially feed in partially (e.g. max 20 recent messages)\n",
    "\n",
    "while True:\n",
    "    current_user_input = input(\"Send a message to the system (type \\\"quit\\\" to exit process): \")\n",
    "    if current_user_input == \"quit\":\n",
    "        message_history = []\n",
    "        break\n",
    "    # Get structure response + retrieve\n",
    "    current_msg_structured = make_user_message_dict(current_user_input)\n",
    "    # query_list_debug = chat_func_debug([sys_msg_structured] + message_history + [current_msg_structured])\n",
    "    # print(query_list_debug)\n",
    "    query_list = structured_func([sys_msg_structured] + message_history + [current_msg_structured], QueryList)\n",
    "    print(query_list)\n",
    "    query_result = process_queries(query_list.root)\n",
    "    \n",
    "    # Perform actural Q&A\n",
    "    current_msg = make_user_message_dict(current_user_input + query_result)\n",
    "    message_history.append(current_msg)\n",
    "    new_msg = chat_func([sys_msg] + message_history)\n",
    "    print_llm_message(new_msg)\n",
    "    message_history.append(new_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FAQ-LLM-bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
